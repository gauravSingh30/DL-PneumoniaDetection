{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c62159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch torchvision\n",
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset\n",
    "print(\"Pytorch version: \", torch.__version__)\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from vit_pytorch import ViT\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b53ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174da956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import MultiheadAttention, Linear, Dropout, BatchNorm1d, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e44e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "import os, re\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from time import time\n",
    "\n",
    "# !pip install \"opencv-python-headless<4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URLs for the zip files\n",
    "# links = [\n",
    "#     'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "#     'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "#     'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "#     'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "#     'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "#     'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "#     'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "#     'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "#     'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "#     'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "#     'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "#     'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "# ]\n",
    "\n",
    "# for idx, link in enumerate(links):\n",
    "#     fn = 'images_%02d.tar.gz' % (idx+1)\n",
    "#     print('downloading'+fn+'...')\n",
    "#     urllib.request.urlretrieve(link, fn)  # download the zip file\n",
    "\n",
    "# print(\"Download complete. Please check the checksums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89850aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://storage.googleapis.com/kaggle-data-sets/17810/23812/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221113%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221113T184826Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=8b97695681cd98618091b81d3f73b7f7bb8dec20f49f0cd975fbebf3f84d23ff72b5daf735fdfabb3712f3515162ad255fb24f90543814881739ea13a12480a27ce0d5bdaab494467327099175916c8fad100df92228d9fb3a7a7b521513bf1834f2aa8b75cebbddcf8c917ce43a4b6bf844f8089d69d1641ef770656248bf2e6cbe871453787d6a68cb4f4a5d11f089cd8258aecf9288d0abf7bdcf3d2f66f8232682285a9897c3757fc1d9e45c941690c63311ec7cadcb701d59e20880dfec26d6cb65aa1be79da4951b10ca6fa11b31ee0c215cfd09b9b1c501a5eb347f269a0f0862452f8b8d6172ee12bfd539590bae599cf375c2b6c30458ff9e13396e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8450349",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'archive.zip'\n",
    "print('downloading'+fn+'...')\n",
    "urllib.request.urlretrieve(link, fn)  # download the zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99354d",
   "metadata": {},
   "source": [
    "#### Extracting the .zip files and accumulatig it into train and test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./archive.zip\"\n",
    "with ZipFile(file, 'r') as zip2:\n",
    "    zip2.printdir()\n",
    "    print(\"Extracting file...\")\n",
    "    \n",
    "    zip2.extractall()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val = pd.read_csv('./train_val_list.txt', header=None)\n",
    "# test = pd.read_csv('./test_list.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d73fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"total images: \", len(train_val) + len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val.rename(columns={0: \"Images\"}, inplace=True)\n",
    "# test.rename(columns={0: \"Images\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc444dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping\n",
    "# mapping = {\n",
    "#      1: \"Atelectasis\",\n",
    "#      2: \"Cardiomegaly\",\n",
    "#      3: \"Effusion\", \n",
    "#      4: \"Infiltration\",\n",
    "#      5: \"Mass\",\n",
    "#      6: \"Nodule\",\n",
    "#      7: \"Pneumonia\", \n",
    "#      8:\"Pneumothorax\",\n",
    "#      9: \"Consolidation\",\n",
    "#      10:\"Edema\",\n",
    "#      11: \"Emphysema\",\n",
    "#      12: \"Fibrosis\",\n",
    "#      13: \"Pleural_Thickening\", \n",
    "#      14: \"Hernia\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_folders = os.listdir('./Extracted/')\n",
    "# all_images = []\n",
    "# all_labels = []\n",
    "# for f in image_folders:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = pd.read_csv('./nih-cxr-lt_single-label_train.csv')\n",
    "# val_labels = pd.read_csv('./nih-cxr-lt_single-label_test.csv')\n",
    "# test_labels = pd.read_csv('./nih-cxr-lt_single-label_balanced-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_labels) + len(train_labels) + len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "val_images = []\n",
    "val_labels = []\n",
    "test_images = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_normal = './chest_xray/train/NORMAL/'\n",
    "train_folder_pne = './chest_xray/train/PNEUMONIA/'\n",
    "\n",
    "val_folder_normal = './chest_xray/val/NORMAL/'\n",
    "val_folder_pne = './chest_xray/val/PNEUMONIA/'\n",
    "\n",
    "test_folder_normal = './chest_xray/test/NORMAL/'\n",
    "test_folder_pne = './chest_xray/test/PNEUMONIA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7596b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = list(os.listdir(train_folder_normal))\n",
    "train_images.extend(list(os.listdir(train_folder_pne)))\n",
    "train_labels = list(np.zeros(len(os.listdir(train_folder_normal))).astype('int'))\n",
    "train_labels.extend(np.ones(len(os.listdir(train_folder_pne))).astype('int'))\n",
    "\n",
    "val_images = list(os.listdir(val_folder_normal))\n",
    "val_images.extend(list(os.listdir(val_folder_pne)))\n",
    "val_labels = list(np.zeros(len(os.listdir(val_folder_normal))).astype('int'))\n",
    "val_labels.extend(np.ones(len(os.listdir(val_folder_pne))).astype('int'))\n",
    "\n",
    "test_images = list(os.listdir(test_folder_normal))\n",
    "test_images.extend(list(os.listdir(test_folder_pne)))\n",
    "test_labels = list(np.zeros(len(os.listdir(test_folder_normal))).astype('int'))\n",
    "test_labels.extend(np.ones(len(os.listdir(test_folder_pne))).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28aee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(zip(train_images, train_labels)), columns=['images', 'label'])\n",
    "val_df = pd.DataFrame(list(zip(val_images, val_labels)), columns=['images', 'label'])\n",
    "test_df = pd.DataFrame(list(zip(test_images, test_labels)), columns=['images', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Since val data is not enough adding few from train data to val data to make it's count = 600.\n",
    "train_df = pd.concat((train_df, val_df), axis = 0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size = 600, stratify=train_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f60b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move validation data to combined folder and also segregate them to the original folder structure\n",
    "\n",
    "val_images = list(val_df['images'].values)\n",
    "for v in val_images:\n",
    "    src = './combined/train/' + v\n",
    "    dest = './combined/val/'\n",
    "    shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c780181",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(train_df['images'].values, train_df['label'].values):\n",
    "    src = './combined/train/' + x\n",
    "    dest = './chest_xray/train/'\n",
    "    if(y == 1):\n",
    "        dest = dest + \"PNEUMONIA\"\n",
    "    else:\n",
    "        dest = dest + \"NORMAL\"\n",
    "    \n",
    "    shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040be5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(val_df['images'].values, val_df['label'].values):\n",
    "    src = './combined/val/' + x\n",
    "    dest = './chest_xray/val/'\n",
    "    if(y == 1):\n",
    "        dest = dest + \"PNEUMONIA\"\n",
    "    else:\n",
    "        dest = dest + \"NORMAL\"\n",
    "    \n",
    "    shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5482b",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55599771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def my_fmt(x):\n",
    "    return '{:.4f}%\\n({:.0f})'.format(x, total*x/100)\n",
    "\n",
    "labels = ['Pneumonia', 'Normal']\n",
    "values = list(train_df['label'].value_counts())\n",
    "total = len(train_df)\n",
    "palette_color = sns.color_palette('YlGnBu')\n",
    "  \n",
    "plt.pie(values, labels = labels, colors=palette_color, autopct=my_fmt,startangle=90)\n",
    "plt.title(\"Train data distribution\")\n",
    "plt.show()\n",
    "\n",
    "labels = ['Pneumonia', 'Normal']\n",
    "values = list(val_df['label'].value_counts())\n",
    "total = len(val_df)\n",
    "palette_color = sns.color_palette('YlGnBu')\n",
    "  \n",
    "plt.pie(values, labels = labels, colors=palette_color, autopct=my_fmt, startangle=90)\n",
    "plt.title(\"Val data distribution\")\n",
    "plt.show()\n",
    "\n",
    "labels = ['Pneumonia', 'Normal']\n",
    "values = list(test_df['label'].value_counts())\n",
    "total = len(test_df)\n",
    "palette_color = sns.color_palette('YlGnBu')\n",
    "  \n",
    "plt.pie(values, labels = labels, colors=palette_color, autopct=my_fmt, startangle=90)\n",
    "plt.title(\"Test data distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling the train, val and test dataframes\n",
    "\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12636efb",
   "metadata": {},
   "source": [
    "#### Visualising the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66575de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleP = list(train_df[train_df['label'] == 1].sample(4)['images'])\n",
    "sampleN = list(train_df[train_df['label'] == 0].sample(4)['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b010307",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "print(\"Train data: Normal Person\")\n",
    "for i in range(0, 4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    img = cv2.imread(\"./combined/train/\" + sampleN[i], cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "print(\"Train data: Pneumonia effected Person\")\n",
    "for i in range(0, 4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    img = cv2.imread(\"./combined/train/\" + sampleP[i], cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f6815",
   "metadata": {},
   "source": [
    "##### Using PCA on flattened resized images 256 x 256 and clustering them into two clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ffc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = []\n",
    "t_names = list(train_df['images'].values)\n",
    "for img in t_names:\n",
    "    i = cv2.imread(\"./combined/train/\" + img, cv2.IMREAD_GRAYSCALE)\n",
    "    i = cv2.resize(i, (256, 256))\n",
    "    i = i / 255\n",
    "    full_train_data.append(i.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_val_data = []\n",
    "t_names = list(val_df['images'].values)\n",
    "for img in t_names:\n",
    "    i = cv2.imread(\"./combined/val/\" + img, cv2.IMREAD_GRAYSCALE)\n",
    "    i = cv2.resize(i, (256, 256))\n",
    "    i = i / 255\n",
    "    full_val_data.append(i.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = []\n",
    "t_names = list(test_df['images'].values)\n",
    "for img in t_names:\n",
    "    i = cv2.imread(\"./combined/test/\" + img, cv2.IMREAD_GRAYSCALE)\n",
    "    i = cv2.resize(i, (256, 256))\n",
    "    i = i / 255\n",
    "    full_test_data.append(i.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90461153",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = np.array(full_train_data)\n",
    "full_test_data = np.array(full_test_data)\n",
    "full_val_data = np.array(full_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd491ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "pca.fit(full_train_data)\n",
    "pca_train = pca.transform(full_train_data)\n",
    "print(\"Time to PCA: \", time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb855e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "pca_test = pca.transform(full_test_data)\n",
    "pca_val = pca.transform(full_val_data)\n",
    "print(\"Time to PCA (test + val): \", time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b628bb",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80919d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1962ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(init = \"k-means++\", n_clusters = 2, n_init = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53057e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "km.fit(pca_train)\n",
    "print(\"Time to K-means: \", time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae623a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "print(np.unique(preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = km.labels_\n",
    "truths = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def getMetrics(truths, preds):\n",
    "    cm = confusion_matrix(truths, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(truths, preds).ravel()\n",
    "    \n",
    "    print(\"Accuracy: \", accuracy_score(truths, preds))\n",
    "    print(\"Precision: \", precision_score(truths, preds))\n",
    "    print(\"Recall: \", recall_score(truths, preds))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Pneumonia'])\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0733d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(truths, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverting the cluster assignments\n",
    "getMetrics(truths, 1 - preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f196b7",
   "metadata": {},
   "source": [
    "##### Clearly the first cluster assignment works better in terms of TP and TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3798b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusters(km, test_data):\n",
    "    test_pca = pca.transform(test_data)\n",
    "    centroids = km.cluster_centers_\n",
    "    preds = []\n",
    "    \n",
    "    for i in range(len(test_pca)):\n",
    "        norm0 = np.linalg.norm(centroids[0] - test_pca[i, :], ord = 2)\n",
    "        norm1 = np.linalg.norm(centroids[1] - test_pca[i, :], ord = 2)\n",
    "        \n",
    "        if(norm0 < norm1):\n",
    "            preds.append(0)\n",
    "        else:\n",
    "            preds.append(1)\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab15209",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = getClusters(km, full_val_data)\n",
    "val_truths = val_df['label'].values\n",
    "getMetrics(val_truths, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = getClusters(km, full_test_data)\n",
    "test_truths = test_df['label'].values\n",
    "getMetrics(test_truths, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose = 1, perplexity=40, n_iter = 300)\n",
    "\n",
    "s = time()\n",
    "tsne_results = tsne.fit_transform(pca_train)\n",
    "print(\"Time to TSNE: \", time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.DataFrame(tsne_results, columns=['x', 'y'])\n",
    "df_subset['label'] = train_df['label'].values\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(\n",
    "    x=\"x\", y=\"y\",\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "plt.title(\"TSNE plot of PCA(98%) Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba7dc0",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "s = time()\n",
    "log_clf = LogisticRegression(random_state=0, penalty = 'l2', C = 1000, class_weight = 'balanced', max_iter = 1000).fit(\n",
    "    full_train_data,\n",
    "    train_df['label'].values\n",
    ")\n",
    "\n",
    "print(\"Time to Logistic: \", time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "log_preds = log_clf.predict(full_test_data)\n",
    "print(\"Time to log test: \", time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(test_truths, log_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197cf541",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "s = time()\n",
    "svc_clf = SVC(C = 1, kernel = 'rbf', gamma = 'scale', class_weight = 'balanced', random_state = 0).fit(\n",
    "    pca_train,\n",
    "    train_df['label'].values\n",
    ")\n",
    "\n",
    "print(\"Time to SVC: \", time() - s)\n",
    "\n",
    "#Poly kernel also tried but didn't do well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = svc_clf.predict(pca_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f667e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(val_truths, svc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "svc_preds = svc_clf.predict(pca_test)\n",
    "print(\"Time to SVC test: \", time() - s)\n",
    "getMetrics(test_truths, svc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a814aa",
   "metadata": {},
   "source": [
    "#### Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db4ce3",
   "metadata": {},
   "source": [
    "##### Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision import models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)\n",
    "''' SEED Everything '''\n",
    "# set computation device\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Computation device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83514c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './combined/train/'\n",
    "val_path = './combined/val/'\n",
    "test_path = './combined/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counting how many are RGB and how many are grayscale images\n",
    "count_rgb = 0\n",
    "count_gray = 0\n",
    "\n",
    "for img in train_df['images'].values:\n",
    "    i = np.array(Image.open(train_path + img))\n",
    "    s = i.shape\n",
    "    if(len(s) == 3):\n",
    "        count_rgb+=1\n",
    "    else:\n",
    "        count_gray+=1\n",
    "\n",
    "print(\"# RGB Images: \", count_rgb)\n",
    "print(\"# GRAY Images: \", count_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37567d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "for img in train_df['images'].values:\n",
    "    i = cv2.imread(\"./combined/train/\" + img, cv2.IMREAD_GRAYSCALE)\n",
    "    i = i / 255\n",
    "    mean = mean + i.mean()\n",
    "    std = std + i.std()\n",
    "\n",
    "mean = mean / len(train_df)\n",
    "std = std / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.4824711976956915\n",
    "std = 0.2233597932720994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of data: \", mean)\n",
    "print(\"Std of data: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6951df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_frame, data_path, tfms=None):\n",
    "        self.X = data_frame['images'].values\n",
    "        self.y = data_frame['label'].values\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        # apply augmentations\n",
    "        if tfms == None: # if validating\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "                albumentations.Normalize(mean=mean,\n",
    "                          std=std, max_pixel_value = 255.0, always_apply=True)\n",
    "            ])\n",
    "        else: # if training\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "                albumentations.HorizontalFlip(p=0.50),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.1,\n",
    "                    rotate_limit=5,\n",
    "                    p=0.50\n",
    "                ),\n",
    "                albumentations.Normalize(mean=mean,\n",
    "                          std=std, max_pixel_value = 255.0, always_apply=True)\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.data_path + self.X[i], cv2.IMREAD_GRAYSCALE)\n",
    "        image = self.aug(image=np.array(image))['image']\n",
    "        image = np.array([image])\n",
    "        label = np.zeros(2)\n",
    "        if(self.y[i] == 0):\n",
    "            label[0] = 1\n",
    "        else:\n",
    "            label[1] = 1\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers = 16)\n",
    "\n",
    "val_dataset = ImageDataset(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers = 16)\n",
    "\n",
    "test_dataset = ImageDataset(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfcdfa6",
   "metadata": {},
   "source": [
    "#### Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de006715",
   "metadata": {},
   "source": [
    "##### CNN\n",
    "\n",
    "- An efficient deep learning approach to pneumonia classification in healthcare\n",
    "- Feature extraction and classification of chest x-ray images using cnn to detect pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.BN1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.BN2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.BN3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, 3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.BN4 = nn.BatchNorm2d(128)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(18432, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.BN1(y)\n",
    "        y = self.pool1(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.BN2(y)\n",
    "        y = self.pool2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.BN3(y)\n",
    "        y = self.pool3(y)\n",
    "        \n",
    "        y = self.conv4(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.BN4(y)\n",
    "        y = self.pool4(y)\n",
    "\n",
    "        y = y.view(y.shape[0], -1)\n",
    "\n",
    "        y = self.drop1(y)\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = self.relu5(y)\n",
    "        \n",
    "        y = self.fc2(y)\n",
    "        y = self.relu6(y)\n",
    "        \n",
    "        y = self.fc3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc17150",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = LeNet(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd577a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4383c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_net = nn.DataParallel(model)\n",
    "le_net.to(device)\n",
    "# le_net = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 50\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-5\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(le_net.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = eps\n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98622582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    le_net.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = le_net(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    le_net.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = le_net(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b69149",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_net.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = le_net(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f1827",
   "metadata": {},
   "source": [
    "##### ChexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dddb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, classCount, isTrained):\n",
    "        super(DenseNet121, self).__init__()\n",
    "\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=isTrained)\n",
    "\n",
    "        kernelCount = self.densenet121.classifier.in_features\n",
    "        \n",
    "        self.densenet121.classifier = nn.Sequential(nn.Linear(kernelCount, classCount))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef960f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet = DenseNet121(2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(denseNet):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491acfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net = nn.DataParallel(denseNet)\n",
    "dense_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95288246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset3D(Dataset):\n",
    "    def __init__(self, data_frame, data_path, tfms=None):\n",
    "        self.X = data_frame['images'].values\n",
    "        self.y = data_frame['label'].values\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        # apply augmentations\n",
    "        if tfms == None: # if validating\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "                albumentations.Normalize(mean=mean,\n",
    "                          std=std, max_pixel_value = 255.0, always_apply=True)\n",
    "            ])\n",
    "        else: # if training\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(224, 224, always_apply=True),\n",
    "                albumentations.HorizontalFlip(p=0.50),\n",
    "                albumentations.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.1,\n",
    "                    rotate_limit=5,\n",
    "                    p=0.50\n",
    "                ),\n",
    "                albumentations.Normalize(mean=mean,\n",
    "                          std=std, max_pixel_value = 255.0, always_apply=True)\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.data_path + self.X[i], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        image = self.aug(image=np.array(image))['image']\n",
    "        image = np.array(image)\n",
    "        image = np.stack([image, image, image])\n",
    "        label = np.zeros(2)\n",
    "        if(self.y[i] == 0):\n",
    "            label[0] = 1\n",
    "        else:\n",
    "            label[1] = 1\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96270a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset3D(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 20)\n",
    "\n",
    "val_dataset = ImageDataset3D(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 20)\n",
    "\n",
    "test_dataset = ImageDataset3D(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-5\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "\n",
    "optimizer = torch.optim.Adam(dense_net.parameters(), lr=lr, betas=(0.9, 0.999), eps=eps, weight_decay=wt_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    dense_net.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = dense_net(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    dense_net.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = dense_net(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    scheduler.step(valid_loss / len(val_loader))\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = dense_net(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb2378",
   "metadata": {},
   "source": [
    "#### Vision based Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633d6a2",
   "metadata": {},
   "source": [
    "###### Simple ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch import SimpleViT, ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.deepvit import DeepViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa676d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 16)\n",
    "\n",
    "val_dataset = ImageDataset(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 16)\n",
    "\n",
    "test_dataset = ImageDataset(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseViT = ViT(\n",
    "    image_size = 224,\n",
    "    patch_size = 16,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 8,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.2,\n",
    "    emb_dropout = 0.2,\n",
    "    channels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba16cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepVit = DeepViT(\n",
    "    image_size = 224,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth =12,\n",
    "    heads = 24,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    channels=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218881fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(baseViT):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(deepVit):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit = nn.DataParallel(baseViT)\n",
    "base_vit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec90ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 40\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-6\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(base_vit.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = eps\n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "warmup_steps = 580\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0f7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    if(e > 30):\n",
    "        break\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    base_vit.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = base_vit(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    base_vit.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = base_vit(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = base_vit(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959509ee",
   "metadata": {},
   "source": [
    "#### DeepVit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5053263",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_vit = nn.DataParallel(deepVit)\n",
    "deep_vit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 32)\n",
    "\n",
    "val_dataset = ImageDataset(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 32)\n",
    "\n",
    "test_dataset = ImageDataset(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 30\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-6\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(deep_vit.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = eps\n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "warmup_steps = 580\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf590952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    if(e > 20):\n",
    "        break\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    deep_vit.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = deep_vit(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    deep_vit.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = deep_vit(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_vit.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = deep_vit(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e1f42",
   "metadata": {},
   "source": [
    "##### Convolution patching (CCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.cct import CCT\n",
    "\n",
    "cct = CCT(\n",
    "    img_size = 224,\n",
    "    embedding_dim = 384,\n",
    "    n_conv_layers = 6,\n",
    "    kernel_size = 7,\n",
    "    stride = 2,\n",
    "    padding = 3,\n",
    "    pooling_kernel_size = 3,\n",
    "    pooling_stride = 2,\n",
    "    pooling_padding = 1,\n",
    "    num_layers = 14,\n",
    "    num_heads = 6,\n",
    "    mlp_radio = 3.,\n",
    "    num_classes = 2,\n",
    "    channels = 3,\n",
    "    positional_embedding = 'learnable', # ['sine', 'learnable', 'none']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99903b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cct_mod = nn.DataParallel(cct)\n",
    "cct_mod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(cct_mod):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset3D(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 20)\n",
    "\n",
    "val_dataset = ImageDataset3D(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 20)\n",
    "\n",
    "test_dataset = ImageDataset3D(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ee5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 30\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-6\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(cct_mod.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = eps\n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "warmup_steps = 580\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb021ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    if(e > 20):\n",
    "        break\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    cct_mod.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = cct_mod(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    cct_mod.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = cct_mod(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cct_mod.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = cct_mod(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f627fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe14bf",
   "metadata": {},
   "source": [
    "### Cross Vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.cross_vit import CrossViT\n",
    "\n",
    "cross = CrossViT(\n",
    "    image_size = 224,\n",
    "    num_classes = 2,\n",
    "    depth = 6,               # number of multi-scale encoding blocks\n",
    "    sm_dim = 192,            # high res dimension\n",
    "    sm_patch_size = 16,      # high res patch size (should be smaller than lg_patch_size)\n",
    "    sm_enc_depth = 2,        # high res depth\n",
    "    sm_enc_heads = 8,        # high res heads\n",
    "    sm_enc_mlp_dim = 2048,   # high res feedforward dimension\n",
    "    lg_dim = 384,            # low res dimension\n",
    "    lg_patch_size = 32,      # low res patch size\n",
    "    lg_enc_depth = 3,        # low res depth\n",
    "    lg_enc_heads = 8,        # low res heads\n",
    "    lg_enc_mlp_dim = 2048,   # low res feedforward dimensions\n",
    "    cross_attn_depth = 2,    # cross attention rounds\n",
    "    cross_attn_heads = 8,    # cross attention heads\n",
    "    dropout = 0.2,\n",
    "    emb_dropout = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_mod = nn.DataParallel(cross)\n",
    "cross_mod.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The model has {count_parameters(cross_mod):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset3D(train_df, train_path, tfms=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 20)\n",
    "\n",
    "val_dataset = ImageDataset3D(val_df, val_path, tfms=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 20)\n",
    "\n",
    "test_dataset = ImageDataset3D(test_df, test_path, tfms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f66956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 30\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n",
    "momentum = 0.9\n",
    "wt_decay = 1e-6\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(cross_mod.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = eps\n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "warmup_steps = 580\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed073256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with Validation\n",
    "for e in range(n_epochs):\n",
    "    if(e > 20):\n",
    "        break\n",
    "    train_loss = 0.0\n",
    "    t_count = 0\n",
    "    v_count = 0\n",
    "    cross_mod.train()\n",
    "    for data, labels in tqdm(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = cross_mod(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        t_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    cross_mod.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in tqdm(val_loader):\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = cross_mod(data)\n",
    "        \n",
    "        ind_preds = torch.argmax(target, 1)\n",
    "        ind_lab = torch.argmax(labels, 1)\n",
    "        v_count+=int(torch.sum(ind_preds == ind_lab).cpu())\n",
    "        \n",
    "        # Find the Loss\n",
    "        loss = criterion(target, labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}:\\nTrain Loss: {}\\nVal Loss: {}\\n\".format(e+1, train_loss / len(train_loader), valid_loss / len(val_loader)))\n",
    "    print(\"Epoch {}:\\nTrain Acc: {}\\nVal Acc: {}\\n\".format(e+1, t_count / len(train_df), v_count / len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31790d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_mod.eval() # Optional when not using Model Specific layer\n",
    "preds = []\n",
    "true_labels = []\n",
    "test_loss = 0.0\n",
    "for data, labels in tqdm(test_loader):\n",
    "    # Transfer Data to GPU if available\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Forward Pass\n",
    "    target = cross_mod(data)\n",
    "\n",
    "    pr = list(torch.argmax(target, 1).detach().cpu().numpy())\n",
    "    ind_lab = list(torch.argmax(labels, 1).detach().cpu().numpy())\n",
    "    \n",
    "    true_labels.extend(ind_lab)\n",
    "    preds.extend(pr)\n",
    "\n",
    "    # Find the Loss\n",
    "    loss = criterion(target, labels)\n",
    "    # Calculate Loss\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(\"Test loss: {}\".format(test_loss / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMetrics(true_labels, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
